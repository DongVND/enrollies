# -*- coding: utf-8 -*-
"""DONG - ETL (Session 5.7: ETL & Logistic Regression)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NgbWKa8OegNPLLrEW8FAF_cfcYKUXFJS
"""

#  Import Pandas at rst to be able to load data to a dataframe:
import pandas as pd

"""Extract - Transform - Loading
1.1. Enrollies ' data
1.2. Enrollies' education
1.3. Enrollies' working experience
1.4. Training hours
1.5. City development index
1.6. Employment
"""

#read data from google sheet
google_sheet_id = '1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI'
url='https://docs.google.com/spreadsheets/d/' + google_sheet_id + '/export?format=xlsx'
enrollies_df = pd.read_excel(url, sheet_name ='enrollies')

# Read data from Excel file
enrollies_education_df = pd.read_excel('/content/enrollies_education.xlsx',sheet_name= 'enrollies_education')
 # Read data from CSV file
work_experience_df = pd.read_csv('/content/work_experience.csv')

#import SQLAlchemy:
from sqlalchemy import create_engine
#install pymysql
!pip install pymysql

#  <driver>://<login>:<password>@<host>:<port>/<database_name>
#  Driver: mysql+pymysql
#  Login: etl_practice
#  Password: 550814
#  Host: 112.213.86.31
#  Port: 3360
#  Database Name: company_course
#  table name: training_hours

engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')

training_hours_df = pd.read_sql_table("training_hours", con=engine)
#altinatively:  training_hours_df = pd.read_sql('SELECT * FROM training_hours', con=engine)
training_hours_df.head()

#add employment table name
# Database name: company_course
# Table name: employment
employment_df = pd.read_sql_table("employment", con=engine)

employment_df.head()

#read a web page table
page_url = "https://sca-programming-school.github.io/city_development_index/index.html"
city_development_index_df = pd.read_html(page_url)[0]

#check table head
city_development_index_df.head()

"""## ***TRANSFORM"""

# enrollies' data
enrollies_df.head()

# What to do/transform:
# fixing data types
# missing value handling
# remove duplicate
# consistency format

enrollies_df.info()

#fix data type for enrollies_df
enrollies_df.full_name = enrollies_df.full_name.astype('string')
enrollies_df.city = enrollies_df.city.astype('string')

enrollies_df.gender.unique()

"""Gender are OK for the categories"""

#fill missing value for enrollies_df
enrollies_df.gender = enrollies_df.gender.fillna(enrollies_df.gender.mode()[0])
enrollies_df.gender = enrollies_df.gender.astype('category')

#check info again for enrollies_df:
enrollies_df.info()

#handling duplicates for enrollies_df, if none we can skip:
enrollies_df.duplicated().sum()

#Enrollies' education
enrollies_education.head()

enrollies_education.info()

enrollies_education.enrolled_university = enrollies_education.enrolled_university.fillna('unknown')
enrollies_education.education_level = enrollies_education.education_level.fillna('unknown')
enrollies_education.major_discipline = enrollies_education.major_discipline.fillna('unknown')

cat_cols = ['enrolled_university','education_level','major_discipline']
enrollies_education[cat_cols] = enrollies_education[cat_cols].astype('category')

enrollies_education.info()

"""

```
# This is formatted as code
```

# Enrollies' working experience"""

work_experience_df.head()

work_experience_df.info()

work_experience_df.experience = work_experience_df.experience.fillna(work_experience_df.experience.mode()[0])
work_experience_df.company_size = work_experience_df.company_size.fillna("unknown")
work_experience_df.company_type = work_experience_df.company_type.fillna("unknown")
work_experience_df.last_new_job = work_experience_df.last_new_job.fillna("unknown")

work_experience_df_cat_cols = ['relevent_experience','company_size','company_type','last_new_job','experience']
work_experience_df[work_experience_df_cat_cols] = work_experience_df[work_experience_df_cat_cols].astype('category')

work_experience_df.info()

#check training_hour
training_hours_df.info()

employment_df.info()

city_development_index_df.info()

"""(!) no problem found for training_hours_df and employment_df and city_development_index_df

# Load Data to database
"""

db= 'data_warehouse.db'
target_db_engine = create_engine('sqlite:///data_warehouse.db')

employment_df.to_sql('Fact_employment', target_db_engine, if_exists='replace',index=False)
enrollies_df.to_sql('dim_enroll',target_db_engine, if_exists='replace',index=False)
enrollies_education_df.to_sql('dim_edu',target_db_engine, if_exists='replace',index=False)
training_hours_df.to_sql('dim_training_hours',target_db_engine, if_exists='replace',index=False)
work_experience_df.to_sql('dim_work_exp',target_db_engine, if_exists='replace',index=False)
city_development_index_df.to_sql('dim_city_dev',target_db_engine, if_exists='replace',index=False)